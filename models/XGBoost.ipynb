{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39cae20",
   "metadata": {},
   "source": [
    "#### Partie 2 : Modélisation et Prédiction avec XGBoost\n",
    "\n",
    "Après avoir réalisé la régression linéaire et Lasso, cette partie du notebook présente une approche avancée de modélisation pour la prédiction du prix des voitures à l’aide de XGBoost, un algorithme de boosting performant pour les tâches de régression.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Importation des bibliothèques**  \n",
    "Les bibliothèques nécessaires pour la manipulation des données, le prétraitement, la modélisation et l’évaluation (pandas, numpy, xgboost, scikit-learn, joblib) sont importées.\n",
    "\n",
    "**2. Chargement et exploration des données**  \n",
    "Le jeu de données nettoyé est chargé, puis examiné pour vérifier sa structure, ses dimensions et l’absence de valeurs manquantes.\n",
    "\n",
    "**3. Gestion des valeurs aberrantes**  \n",
    "Les valeurs extrêmes du prix sont identifiées et supprimées à l’aide de la méthode de l’écart interquartile (IQR), afin d’améliorer la robustesse du modèle.\n",
    "\n",
    "**4. Prétraitement des données**  \n",
    "- Sélection des caractéristiques pertinentes pour la prédiction.\n",
    "- Encodage des variables catégorielles avec LabelEncoder, car XGBoost ne gère pas directement les textes.\n",
    "- Mise à l’échelle des variables numériques avec StandardScaler pour homogénéiser les échelles.\n",
    "\n",
    "**5. Division du jeu de données**  \n",
    "Les données sont séparées en ensembles d’entraînement (80%) et de test (20%) pour évaluer la performance du modèle sur des données non vues.\n",
    "\n",
    "**6. Entraînement du modèle XGBoost**  \n",
    "Un modèle XGBoostRegressor est entraîné sur les données prétraitées.\n",
    "\n",
    "**7. Prédiction et évaluation**  \n",
    "- Prédiction des prix sur l’ensemble de test.\n",
    "- Calcul des métriques d’évaluation : MAE, RMSE et R² pour mesurer la qualité des prédictions.\n",
    "- Visualisation de l’importance des caractéristiques pour comprendre les variables les plus influentes.\n",
    "- Comparaison des valeurs réelles et prédites sur un échantillon.\n",
    "\n",
    "**8. Prédiction sur une nouvelle voiture**  \n",
    "Le notebook montre comment préparer les données d’un nouveau véhicule, appliquer les mêmes transformations, puis prédire son prix avec le modèle entraîné.\n",
    "\n",
    "**9. Sauvegarde du modèle et des objets de prétraitement**  \n",
    "Le modèle, le scaler, les encoders et la liste des colonnes sont sauvegardés pour une utilisation future sans avoir à refaire tout le pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "Cette démarche permet d’obtenir un modèle robuste, réutilisable et performant pour la prédiction du prix des voitures d’occasion à partir de leurs caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49701689",
   "metadata": {},
   "source": [
    "**Importer les bibliothèques nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b2de435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f535ed0",
   "metadata": {},
   "source": [
    "**Chargement des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb6f47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fuel options: ['Essence' 'Diesel' 'Hybride' 'Electrique' 'LPG']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Lecture du fichier nettoyé\n",
    "# Définir le chemin relatif à la racine du projet\n",
    "project_root = os.path.dirname(os.path.abspath(''))\n",
    "data_path = os.path.join(project_root, 'data', 'avito_cars_clean.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Afficher les cinq premières lignes des données\n",
    "df.head()\n",
    "\n",
    "fuel_options = df['carburant'].unique()\n",
    "print(\"Available fuel options:\", fuel_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471cb11f",
   "metadata": {},
   "source": [
    "**Examen des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5d4aa807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des données : (68415, 11)\n",
      "Statistiques des prix : Min=5200, Max=1000000, Moyenne=138682.62904333844\n",
      "Colonnes : ['annee', 'boite', 'carburant', 'kilometrage', 'marque', 'modele', 'nombre_portres', 'premiere_main', 'puissance_fiscale', 'etat', 'prix']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensions des données : {df.shape}\")\n",
    "print(f\"Statistiques des prix : Min={df['prix'].min()}, Max={df['prix'].max()}, Moyenne={df['prix'].mean()}\")\n",
    "print(f\"Colonnes : {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e39ff0",
   "metadata": {},
   "source": [
    "**Vérifier et nettoyer les données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd9f2bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68415 entries, 0 to 68414\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   annee              68415 non-null  int64  \n",
      " 1   boite              68415 non-null  object \n",
      " 2   carburant          68415 non-null  object \n",
      " 3   kilometrage        68415 non-null  float64\n",
      " 4   marque             68415 non-null  object \n",
      " 5   modele             68415 non-null  object \n",
      " 6   nombre_portres     68415 non-null  int64  \n",
      " 7   premiere_main      68415 non-null  object \n",
      " 8   puissance_fiscale  68415 non-null  int64  \n",
      " 9   etat               68415 non-null  object \n",
      " 10  prix               68415 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "annee                0\n",
      "boite                0\n",
      "carburant            0\n",
      "kilometrage          0\n",
      "marque               0\n",
      "modele               0\n",
      "nombre_portres       0\n",
      "premiere_main        0\n",
      "puissance_fiscale    0\n",
      "etat                 0\n",
      "prix                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81812b74",
   "metadata": {},
   "source": [
    "***Cela signifie que les données sont bien structurées et prêtes pour l'analyse, et qu’il n’y a pas de données manquantes à traiter.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4b661",
   "metadata": {},
   "source": [
    "**Gestion des valeurs aberrantes (AVANT la division des données)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94d15812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage des prix entre -95505.0 et 332503.0\n",
      "Valeurs aberrantes supprimées : 4041\n"
     ]
    }
   ],
   "source": [
    "Q1 = df['prix'].quantile(0.25)\n",
    "Q3 = df['prix'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "print(f\"Filtrage des prix entre {lower_bound} et {upper_bound}\")\n",
    "df_filtered = df[(df['prix'] >= lower_bound) & (df['prix'] <= upper_bound)]\n",
    "print(f\"Valeurs aberrantes supprimées : {df.shape[0] - df_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630ce0a",
   "metadata": {},
   "source": [
    "**Sélection des caractéristiques et prétraitement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d92cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder toutes les caractéristiques utilisées dans Lasso/LR\n",
    "features = ['annee', 'kilometrage', 'puissance_fiscale', 'etat', 'marque', 'modele', 'boite', 'carburant', 'nombre_portres', 'premiere_main']\n",
    "target = 'prix'\n",
    "\n",
    "# Création de X et y\n",
    "X = df_filtered[features]\n",
    "y = df_filtered[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9388a",
   "metadata": {},
   "source": [
    "***XGBoost ne gère pas les textes directement, donc on convertit les colonnes textuelles en chiffres.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16e23367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded etat with 7 unique values\n",
      "Encoded marque with 70 unique values\n",
      "Encoded modele with 770 unique values\n",
      "Encoded boite with 2 unique values\n",
      "Encoded carburant with 5 unique values\n",
      "Encoded premiere_main with 2 unique values\n"
     ]
    }
   ],
   "source": [
    "# Encodage des variables catégorielles\n",
    "categorical_cols = ['etat', 'marque', 'modele', 'boite', 'carburant', 'premiere_main']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X.loc[:, col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Print the encoders for debugging\n",
    "for col, encoder in label_encoders.items():\n",
    "    print(f\"Encoded {col} with {len(encoder.classes_)} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3554a4b",
   "metadata": {},
   "source": [
    "**Suppression des lignes avec des valeurs manquantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b04cdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3554a4b",
   "metadata": {},
   "source": [
    "**On va entraîner le modèle sur 80% des données et tester sur 20%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9f6dc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e100c",
   "metadata": {},
   "source": [
    "**Mise à l'échelle des caractéristiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8018cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numeric_cols = ['annee', 'kilometrage', 'puissance_fiscale', 'nombre_portres']\n",
    "X_train_numeric = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_numeric = scaler.transform(X_test[numeric_cols])\n",
    "    \n",
    "# Conversion en DataFrame pour faciliter la manipulation\n",
    "X_train_numeric_df = pd.DataFrame(X_train_numeric, columns=numeric_cols, index=X_train.index)\n",
    "X_test_numeric_df = pd.DataFrame(X_test_numeric, columns=numeric_cols, index=X_test.index)\n",
    "    \n",
    "# Remplacement des colonnes numériques par leurs versions mises à l'échelle\n",
    "for col in numeric_cols:\n",
    "    X_train[col] = X_train_numeric_df[col]\n",
    "    X_test[col] = X_test_numeric_df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91046bf2",
   "metadata": {},
   "source": [
    "**Création et entraînement du modèle XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77228dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assurez-vous que toutes les colonnes catégorielles sont bien de type int\n",
    "for col in categorical_cols:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61fc47",
   "metadata": {},
   "source": [
    "**Prédictions avec les données de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "282ac82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c25d25",
   "metadata": {},
   "source": [
    "**Évaluation du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e26b186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance du modèle XGBoost :\n",
      "Erreur absolue moyenne (MAE) : 16616.11\n",
      "Erreur quadratique moyenne (RMSE) : 25671.76\n",
      "R² (coefficient de détermination) : 0.8703\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "print(\"\\nPerformance du modèle XGBoost :\")\n",
    "print(f\"Erreur absolue moyenne (MAE) : {mae:.2f}\")\n",
    "print(f\"Erreur quadratique moyenne (RMSE) : {rmse:.2f}\")\n",
    "print(f\"R² (coefficient de détermination) : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70104fac",
   "metadata": {},
   "source": [
    "**Visualisation de l'importance des caractéristiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "daedd9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importance des caractéristiques :\n",
      "             Feature  Importance\n",
      "6              boite    0.433601\n",
      "0              annee    0.338555\n",
      "7          carburant    0.057080\n",
      "2  puissance_fiscale    0.048902\n",
      "4             marque    0.032758\n",
      "9      premiere_main    0.031120\n",
      "5             modele    0.023275\n",
      "3               etat    0.018635\n",
      "8     nombre_portres    0.008430\n",
      "1        kilometrage    0.007644\n"
     ]
    }
   ],
   "source": [
    "importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "    \n",
    "# Créer un DataFrame pour l'importance des caractéristiques\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "print(\"\\nImportance des caractéristiques :\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa778ef",
   "metadata": {},
   "source": [
    "**Comparaison des valeurs prédites vs réelles (échantillon)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9ba4c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparaison des prédictions (20 premiers exemples) :\n",
      "      Réel         Prédit    Différence\n",
      "0    65000   68464.453125  -3464.453125\n",
      "1    58000   69980.171875 -11980.171875\n",
      "2   165000  156716.390625   8283.609375\n",
      "3   250000  275530.718750 -25530.718750\n",
      "4    65000   54984.636719  10015.363281\n",
      "5    27000   27971.070312   -971.070312\n",
      "6    50000   50752.527344   -752.527344\n",
      "7   148000  146226.609375   1773.390625\n",
      "8   217000  178651.484375  38348.515625\n",
      "9    85000   89047.109375  -4047.109375\n",
      "10   45000   44099.964844    900.035156\n",
      "11  330000  261626.984375  68373.015625\n",
      "12  135000  117109.640625  17890.359375\n",
      "13  120000  122523.757812  -2523.757812\n",
      "14  180000  165431.953125  14568.046875\n",
      "15   52000   51863.378906    136.621094\n",
      "16  105000  103265.312500   1734.687500\n",
      "17  290000  274928.937500  15071.062500\n",
      "18   90000   98227.492188  -8227.492188\n",
      "19   83000   80396.601562   2603.398438\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Réel': y_test.values[:20],\n",
    "    'Prédit': y_pred[:20],\n",
    "    'Différence': y_test.values[:20] - y_pred[:20]\n",
    "})\n",
    "print(\"\\nComparaison des prédictions (20 premiers exemples) :\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa778ef",
   "metadata": {},
   "source": [
    "**Prédiction pour une nouvelle voiture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d3564c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Price for Volkswagen Tiguan (2009, 200000 km, 8 CV, Automatique, Diesel, Excellent):\n",
      "XGBoost: 92567.20 MAD\n"
     ]
    }
   ],
   "source": [
    "# Predict price for new car: Volkswagen Tiguan, 2009, 200000 km, 8 CV, Automatique, Diesel, Excellent\n",
    "new_car = pd.DataFrame({\n",
    "    'annee': [2009],\n",
    "    'kilometrage': [200000],\n",
    "    'puissance_fiscale': [8],\n",
    "    'etat': ['Excellent'],\n",
    "    'marque': ['Volkswagen'],\n",
    "    'modele': ['Tiguan'],\n",
    "    'boite': ['Automatique'],\n",
    "    'carburant': ['Diesel'],\n",
    "    'nombre_portres': [5],\n",
    "    'premiere_main': ['Non']\n",
    "})\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "categorical_cols = ['etat', 'marque', 'modele', 'boite', 'carburant', 'premiere_main']\n",
    "for col in categorical_cols:\n",
    "    if col in new_car.columns:\n",
    "        le = label_encoders[col]\n",
    "        # Handle unseen labels by assigning a default value (e.g., mode of encoded values)\n",
    "        new_car[col] = new_car[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "        new_car[col] = le.transform(new_car[col])\n",
    "\n",
    "# Scale numerical features\n",
    "numeric_cols = ['annee', 'kilometrage', 'puissance_fiscale', 'nombre_portres']\n",
    "new_car_numeric = scaler.transform(new_car[numeric_cols])\n",
    "new_car_numeric_df = pd.DataFrame(new_car_numeric, columns=numeric_cols, index=new_car.index)\n",
    "\n",
    "# Replace numerical columns with scaled values\n",
    "for col in numeric_cols:\n",
    "    new_car[col] = new_car_numeric_df[col]\n",
    "\n",
    "# Ensure the new car has the same columns as training data\n",
    "new_car = new_car[X.columns]\n",
    "\n",
    "# Make prediction\n",
    "xgb_pred = model.predict(new_car)\n",
    "\n",
    "# Print predicted price in MAD\n",
    "print(\"\\nPredicted Price for Volkswagen Tiguan (2009, 200000 km, 8 CV, Automatique, Diesel, Excellent):\")\n",
    "print(f\"XGBoost: {xgb_pred[0]:.2f} MAD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa778ef",
   "metadata": {},
   "source": [
    "**Sauvegarde du modèle et des objets nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2d3564c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le scaler, le modèle, les colonnes et les label encoders ont été sauvegardés sous forme de fichiers .pkl.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le scaler\n",
    "# Définir le chemin du dossier pkl à la racine du projet\n",
    "pkl_dir = os.path.join(project_root, 'pkl-files')\n",
    "os.makedirs(pkl_dir, exist_ok=True)\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "joblib.dump(scaler, os.path.join(pkl_dir, 'xgboost_scaler.pkl'))\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "joblib.dump(model, os.path.join(pkl_dir, 'xgboost_model.pkl'))\n",
    "\n",
    "# Sauvegarder les colonnes utilisées\n",
    "joblib.dump(X.columns, os.path.join(pkl_dir, 'xgboost_columns.pkl'))\n",
    "\n",
    "# Sauvegarder les label encoders\n",
    "joblib.dump(label_encoders, os.path.join(pkl_dir, 'xgboost_label_encoders.pkl'))\n",
    "\n",
    "print(\"Le scaler, le modèle, les colonnes et les label encoders ont été sauvegardés sous forme de fichiers .pkl.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710ac89",
   "metadata": {},
   "source": [
    "**Travail Réalisé par EL ANNASI Nada et EL-GHEFYRY Salma**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
