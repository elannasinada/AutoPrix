{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39cae20",
   "metadata": {},
   "source": [
    "#### Partie 2 : Modélisation et Prédiction avec XGBoost\n",
    "\n",
    "Après avoir réalisé la régression linéaire et Lasso, cette partie du notebook présente une approche avancée de modélisation pour la prédiction du prix des voitures à l’aide de XGBoost, un algorithme de boosting performant pour les tâches de régression.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Importation des bibliothèques**  \n",
    "Les bibliothèques nécessaires pour la manipulation des données, le prétraitement, la modélisation et l’évaluation (pandas, numpy, xgboost, scikit-learn, joblib) sont importées.\n",
    "\n",
    "**2. Chargement et exploration des données**  \n",
    "Le jeu de données nettoyé est chargé, puis examiné pour vérifier sa structure, ses dimensions et l’absence de valeurs manquantes.\n",
    "\n",
    "**3. Gestion des valeurs aberrantes**  \n",
    "Les valeurs extrêmes du prix sont identifiées et supprimées à l’aide de la méthode de l’écart interquartile (IQR), afin d’améliorer la robustesse du modèle.\n",
    "\n",
    "**4. Prétraitement des données**  \n",
    "- Sélection des caractéristiques pertinentes pour la prédiction.\n",
    "- Encodage des variables catégorielles avec LabelEncoder, car XGBoost ne gère pas directement les textes.\n",
    "- Mise à l’échelle des variables numériques avec StandardScaler pour homogénéiser les échelles.\n",
    "\n",
    "**5. Division du jeu de données**  \n",
    "Les données sont séparées en ensembles d’entraînement (80%) et de test (20%) pour évaluer la performance du modèle sur des données non vues.\n",
    "\n",
    "**6. Entraînement du modèle XGBoost**  \n",
    "Un modèle XGBoostRegressor est entraîné sur les données prétraitées.\n",
    "\n",
    "**7. Prédiction et évaluation**  \n",
    "- Prédiction des prix sur l’ensemble de test.\n",
    "- Calcul des métriques d’évaluation : MAE, RMSE et R² pour mesurer la qualité des prédictions.\n",
    "- Visualisation de l’importance des caractéristiques pour comprendre les variables les plus influentes.\n",
    "- Comparaison des valeurs réelles et prédites sur un échantillon.\n",
    "\n",
    "**8. Prédiction sur une nouvelle voiture**  \n",
    "Le notebook montre comment préparer les données d’un nouveau véhicule, appliquer les mêmes transformations, puis prédire son prix avec le modèle entraîné.\n",
    "\n",
    "**9. Sauvegarde du modèle et des objets de prétraitement**  \n",
    "Le modèle, le scaler, les encoders et la liste des colonnes sont sauvegardés pour une utilisation future sans avoir à refaire tout le pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "Cette démarche permet d’obtenir un modèle robuste, réutilisable et performant pour la prédiction du prix des voitures d’occasion à partir de leurs caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49701689",
   "metadata": {},
   "source": [
    "**Importer les bibliothèques nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b2de435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f535ed0",
   "metadata": {},
   "source": [
    "**Chargement des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb6f47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fuel options: ['Essence' 'Diesel' 'Hybride' 'Electrique' 'LPG']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Lecture du fichier nettoyé\n",
    "# Définir le chemin relatif à la racine du projet\n",
    "project_root = os.path.dirname(os.path.abspath(''))\n",
    "data_path = os.path.join(project_root, 'data', 'avito_cars_clean.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Afficher les cinq premières lignes des données\n",
    "df.head()\n",
    "\n",
    "fuel_options = df['carburant'].unique()\n",
    "print(\"Available fuel options:\", fuel_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471cb11f",
   "metadata": {},
   "source": [
    "**Examen des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d4aa807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des données : (68415, 11)\n",
      "Statistiques des prix : Min=5200, Max=1000000, Moyenne=138682.62904333844\n",
      "Colonnes : ['annee', 'boite', 'carburant', 'kilometrage', 'marque', 'modele', 'nombre_portres', 'premiere_main', 'puissance_fiscale', 'etat', 'prix']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensions des données : {df.shape}\")\n",
    "print(f\"Statistiques des prix : Min={df['prix'].min()}, Max={df['prix'].max()}, Moyenne={df['prix'].mean()}\")\n",
    "print(f\"Colonnes : {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e39ff0",
   "metadata": {},
   "source": [
    "**Vérifier et nettoyer les données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd9f2bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68415 entries, 0 to 68414\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   annee              68415 non-null  int64  \n",
      " 1   boite              68415 non-null  object \n",
      " 2   carburant          68415 non-null  object \n",
      " 3   kilometrage        68415 non-null  float64\n",
      " 4   marque             68415 non-null  object \n",
      " 5   modele             68415 non-null  object \n",
      " 6   nombre_portres     68415 non-null  int64  \n",
      " 7   premiere_main      68415 non-null  object \n",
      " 8   puissance_fiscale  68415 non-null  int64  \n",
      " 9   etat               68415 non-null  object \n",
      " 10  prix               68415 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "annee                0\n",
      "boite                0\n",
      "carburant            0\n",
      "kilometrage          0\n",
      "marque               0\n",
      "modele               0\n",
      "nombre_portres       0\n",
      "premiere_main        0\n",
      "puissance_fiscale    0\n",
      "etat                 0\n",
      "prix                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81812b74",
   "metadata": {},
   "source": [
    "***Cela signifie que les données sont bien structurées et prêtes pour l'analyse, et qu’il n’y a pas de données manquantes à traiter.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4b661",
   "metadata": {},
   "source": [
    "**Gestion des valeurs aberrantes (AVANT la division des données)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94d15812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrage des prix entre -95505.0 et 332503.0\n",
      "Valeurs aberrantes supprimées : 4041\n"
     ]
    }
   ],
   "source": [
    "Q1 = df['prix'].quantile(0.25)\n",
    "Q3 = df['prix'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "print(f\"Filtrage des prix entre {lower_bound} et {upper_bound}\")\n",
    "df_filtered = df[(df['prix'] >= lower_bound) & (df['prix'] <= upper_bound)]\n",
    "print(f\"Valeurs aberrantes supprimées : {df.shape[0] - df_filtered.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630ce0a",
   "metadata": {},
   "source": [
    "**Sélection des caractéristiques et prétraitement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d92cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder toutes les caractéristiques utilisées dans Lasso/LR\n",
    "features = ['annee', 'kilometrage', 'puissance_fiscale', 'etat', 'marque', 'modele', 'boite', 'carburant', 'nombre_portres', 'premiere_main']\n",
    "target = 'prix'\n",
    "\n",
    "# Création de X et y\n",
    "X = df_filtered[features]\n",
    "y = df_filtered[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9388a",
   "metadata": {},
   "source": [
    "***XGBoost ne gère pas les textes directement, donc on convertit les colonnes textuelles en chiffres.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16e23367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded etat with 7 unique values\n",
      "Encoded marque with 70 unique values\n",
      "Encoded modele with 770 unique values\n",
      "Encoded boite with 2 unique values\n",
      "Encoded carburant with 5 unique values\n",
      "Encoded premiere_main with 2 unique values\n"
     ]
    }
   ],
   "source": [
    "# Encodage des variables catégorielles\n",
    "categorical_cols = ['etat', 'marque', 'modele', 'boite', 'carburant', 'premiere_main']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X.loc[:, col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Print the encoders for debugging\n",
    "for col, encoder in label_encoders.items():\n",
    "    print(f\"Encoded {col} with {len(encoder.classes_)} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3554a4b",
   "metadata": {},
   "source": [
    "**Suppression des lignes avec des valeurs manquantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b04cdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()\n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3554a4b",
   "metadata": {},
   "source": [
    "**On va entraîner le modèle sur 80% des données et tester sur 20%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f6dc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e100c",
   "metadata": {},
   "source": [
    "**Mise à l'échelle des caractéristiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8018cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numeric_cols = ['annee', 'kilometrage', 'puissance_fiscale', 'nombre_portres']\n",
    "X_train_numeric = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_numeric = scaler.transform(X_test[numeric_cols])\n",
    "    \n",
    "# Conversion en DataFrame pour faciliter la manipulation\n",
    "X_train_numeric_df = pd.DataFrame(X_train_numeric, columns=numeric_cols, index=X_train.index)\n",
    "X_test_numeric_df = pd.DataFrame(X_test_numeric, columns=numeric_cols, index=X_test.index)\n",
    "    \n",
    "# Remplacement des colonnes numériques par leurs versions mises à l'échelle\n",
    "for col in numeric_cols:\n",
    "    X_train[col] = X_train_numeric_df[col]\n",
    "    X_test[col] = X_test_numeric_df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91046bf2",
   "metadata": {},
   "source": [
    "**Création et entraînement du modèle XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "77228dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:etat: object, marque: object, modele: object, boite: object, carburant: object, premiere_main: object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\data.py:407\u001b[39m, in \u001b[36mpandas_feature_info\u001b[39m\u001b[34m(data, meta, feature_names, feature_types, enable_categorical)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     new_feature_types.append(\u001b[43m_pandas_dtype_mapper\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'object'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m model = xgb.XGBRegressor(\n\u001b[32m      2\u001b[39m     objective=\u001b[33m'\u001b[39m\u001b[33mreg:squarederror\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      3\u001b[39m     n_estimators=\u001b[32m100\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1222\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1217\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1218\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1219\u001b[39m )\n\u001b[32m   1221\u001b[39m evals_result: TrainingCallback.EvalsLog = {}\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m train_dmatrix, evals = \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1242\u001b[39m     obj: Optional[Objective] = _objective_decorator(\u001b[38;5;28mself\u001b[39m.objective)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:628\u001b[39m, in \u001b[36m_wrap_evaluation_matrices\u001b[39m\u001b[34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_evaluation_matrices\u001b[39m(\n\u001b[32m    608\u001b[39m     *,\n\u001b[32m    609\u001b[39m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m     feature_types: Optional[FeatureTypes],\n\u001b[32m    625\u001b[39m ) -> Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m    626\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[33;03m    way.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m     train_dmatrix = \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    642\u001b[39m     n_validation = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) -> Sequence:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1137\u001b[39m, in \u001b[36mXGBModel._create_dmatrix\u001b[39m\u001b[34m(self, ref, **kwargs)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _can_use_qdm(\u001b[38;5;28mself\u001b[39m.tree_method, \u001b[38;5;28mself\u001b[39m.device) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.booster != \u001b[33m\"\u001b[39m\u001b[33mgblinear\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantileDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bin\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bin\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1140\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:1614\u001b[39m, in \u001b[36mQuantileDMatrix.__init__\u001b[39m\u001b[34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, max_quantile_batches, data_split_mode)\u001b[39m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1595\u001b[39m         info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1607\u001b[39m         )\n\u001b[32m   1608\u001b[39m     ):\n\u001b[32m   1609\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIf data iterator is used as input, data like label should be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mspecified as batch argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1612\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_lower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabel_upper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_quantile_blocks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_quantile_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:1678\u001b[39m, in \u001b[36mQuantileDMatrix._init\u001b[39m\u001b[34m(self, data, ref, enable_categorical, max_quantile_blocks, **meta)\u001b[39m\n\u001b[32m   1663\u001b[39m config = make_jcargs(\n\u001b[32m   1664\u001b[39m     nthread=\u001b[38;5;28mself\u001b[39m.nthread,\n\u001b[32m   1665\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1666\u001b[39m     max_bin=\u001b[38;5;28mself\u001b[39m.max_bin,\n\u001b[32m   1667\u001b[39m     max_quantile_blocks=max_quantile_blocks,\n\u001b[32m   1668\u001b[39m )\n\u001b[32m   1669\u001b[39m ret = _LIB.XGQuantileDMatrixCreateFromCallback(\n\u001b[32m   1670\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1671\u001b[39m     it.proxy.handle,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1676\u001b[39m     ctypes.byref(handle),\n\u001b[32m   1677\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1678\u001b[39m \u001b[43mit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[38;5;66;03m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[32m   1680\u001b[39m _check_call(ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:572\u001b[39m, in \u001b[36mDataIter.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    570\u001b[39m exc = \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    571\u001b[39m \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:553\u001b[39m, in \u001b[36mDataIter._handle_exception\u001b[39m\u001b[34m(self, fn, dft_ret)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dft_ret\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;66;03m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[32m    556\u001b[39m     \u001b[38;5;66;03m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[32m    557\u001b[39m     \u001b[38;5;66;03m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[32m    558\u001b[39m     tb = sys.exc_info()[\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:640\u001b[39m, in \u001b[36mDataIter._next_wrapper.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28mself\u001b[39m._temporary_data = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_exception(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m), \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\data.py:1654\u001b[39m, in \u001b[36mSingleBatchInternalIter.next\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m   1652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28mself\u001b[39m.it += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1654\u001b[39m \u001b[43minput_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[39m, in \u001b[36mDataIter._next_wrapper.<locals>.input_data\u001b[39m\u001b[34m(data, feature_names, feature_types, **kwargs)\u001b[39m\n\u001b[32m    618\u001b[39m     new, cat_codes, feature_names, feature_types = \u001b[38;5;28mself\u001b[39m._temporary_data\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m     new, cat_codes, feature_names, feature_types = \u001b[43m_proxy_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_enable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28mself\u001b[39m._temporary_data = (new, cat_codes, feature_names, feature_types)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\data.py:1707\u001b[39m, in \u001b[36m_proxy_transform\u001b[39m\u001b[34m(data, feature_names, feature_types, enable_categorical)\u001b[39m\n\u001b[32m   1705\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_pa, \u001b[38;5;28;01mNone\u001b[39;00m, feature_names, feature_types\n\u001b[32m   1706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[32m-> \u001b[39m\u001b[32m1707\u001b[39m     df, feature_names, feature_types = \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df, \u001b[38;5;28;01mNone\u001b[39;00m, feature_names, feature_types\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mValue type is not supported for data iterator:\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(data)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\data.py:640\u001b[39m, in \u001b[36m_transform_pandas_df\u001b[39m\u001b[34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.columns) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _matrix_meta:\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot have multiple columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m feature_names, feature_types = \u001b[43mpandas_feature_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    644\u001b[39m arrays = pandas_transform_data(data)\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PandasTransformed(arrays), feature_names, feature_types\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\data.py:409\u001b[39m, in \u001b[36mpandas_feature_info\u001b[39m\u001b[34m(data, meta, feature_names, feature_types, enable_categorical)\u001b[39m\n\u001b[32m    407\u001b[39m             new_feature_types.append(_pandas_dtype_mapper[dtype.name])\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m             \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    412\u001b[39m     feature_types = new_feature_types\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Downloads\\AutoPrix\\venv\\Lib\\site-packages\\xgboost\\data.py:372\u001b[39m, in \u001b[36m_invalid_dataframe_dtype\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    370\u001b[39m type_err = \u001b[33m\"\u001b[39m\u001b[33mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:etat: object, marque: object, modele: object, boite: object, carburant: object, premiere_main: object"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "    \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61fc47",
   "metadata": {},
   "source": [
    "**Prédictions avec les données de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ac82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c25d25",
   "metadata": {},
   "source": [
    "**Évaluation du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance du modèle XGBoost :\n",
      "Erreur absolue moyenne (MAE) : 16616.11\n",
      "Erreur quadratique moyenne (RMSE) : 25671.76\n",
      "R² (coefficient de détermination) : 0.8703\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "print(\"\\nPerformance du modèle XGBoost :\")\n",
    "print(f\"Erreur absolue moyenne (MAE) : {mae:.2f}\")\n",
    "print(f\"Erreur quadratique moyenne (RMSE) : {rmse:.2f}\")\n",
    "print(f\"R² (coefficient de détermination) : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70104fac",
   "metadata": {},
   "source": [
    "**Visualisation de l'importance des caractéristiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daedd9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importance des caractéristiques :\n",
      "             Feature  Importance\n",
      "6              boite    0.433601\n",
      "0              annee    0.338555\n",
      "7          carburant    0.057080\n",
      "2  puissance_fiscale    0.048902\n",
      "4             marque    0.032758\n",
      "9      premiere_main    0.031120\n",
      "5             modele    0.023275\n",
      "3               etat    0.018635\n",
      "8     nombre_portres    0.008430\n",
      "1        kilometrage    0.007644\n"
     ]
    }
   ],
   "source": [
    "importance = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "    \n",
    "# Créer un DataFrame pour l'importance des caractéristiques\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importance\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "print(\"\\nImportance des caractéristiques :\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa778ef",
   "metadata": {},
   "source": [
    "**Comparaison des valeurs prédites vs réelles (échantillon)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4c60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparaison des prédictions (20 premiers exemples) :\n",
      "      Réel         Prédit    Différence\n",
      "0    65000   68464.453125  -3464.453125\n",
      "1    58000   69980.171875 -11980.171875\n",
      "2   165000  156716.390625   8283.609375\n",
      "3   250000  275530.718750 -25530.718750\n",
      "4    65000   54984.636719  10015.363281\n",
      "5    27000   27971.070312   -971.070312\n",
      "6    50000   50752.527344   -752.527344\n",
      "7   148000  146226.609375   1773.390625\n",
      "8   217000  178651.484375  38348.515625\n",
      "9    85000   89047.109375  -4047.109375\n",
      "10   45000   44099.964844    900.035156\n",
      "11  330000  261626.984375  68373.015625\n",
      "12  135000  117109.640625  17890.359375\n",
      "13  120000  122523.757812  -2523.757812\n",
      "14  180000  165431.953125  14568.046875\n",
      "15   52000   51863.378906    136.621094\n",
      "16  105000  103265.312500   1734.687500\n",
      "17  290000  274928.937500  15071.062500\n",
      "18   90000   98227.492188  -8227.492188\n",
      "19   83000   80396.601562   2603.398438\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Réel': y_test.values[:20],\n",
    "    'Prédit': y_pred[:20],\n",
    "    'Différence': y_test.values[:20] - y_pred[:20]\n",
    "})\n",
    "print(\"\\nComparaison des prédictions (20 premiers exemples) :\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa778ef",
   "metadata": {},
   "source": [
    "**Prédiction pour une nouvelle voiture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3564c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Price for Volkswagen Tiguan (2009, 200000 km, 8 CV, Automatique, Diesel, Excellent):\n",
      "XGBoost: 92567.20 MAD\n"
     ]
    }
   ],
   "source": [
    "# Predict price for new car: Volkswagen Tiguan, 2009, 200000 km, 8 CV, Automatique, Diesel, Excellent\n",
    "new_car = pd.DataFrame({\n",
    "    'annee': [2009],\n",
    "    'kilometrage': [200000],\n",
    "    'puissance_fiscale': [8],\n",
    "    'etat': ['Excellent'],\n",
    "    'marque': ['Volkswagen'],\n",
    "    'modele': ['Tiguan'],\n",
    "    'boite': ['Automatique'],\n",
    "    'carburant': ['Diesel'],\n",
    "    'nombre_portres': [5],\n",
    "    'premiere_main': ['Non']\n",
    "})\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "categorical_cols = ['etat', 'marque', 'modele', 'boite', 'carburant', 'premiere_main']\n",
    "for col in categorical_cols:\n",
    "    if col in new_car.columns:\n",
    "        le = label_encoders[col]\n",
    "        # Handle unseen labels by assigning a default value (e.g., mode of encoded values)\n",
    "        new_car[col] = new_car[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "        new_car[col] = le.transform(new_car[col])\n",
    "\n",
    "# Scale numerical features\n",
    "numeric_cols = ['annee', 'kilometrage', 'puissance_fiscale', 'nombre_portres']\n",
    "new_car_numeric = scaler.transform(new_car[numeric_cols])\n",
    "new_car_numeric_df = pd.DataFrame(new_car_numeric, columns=numeric_cols, index=new_car.index)\n",
    "\n",
    "# Replace numerical columns with scaled values\n",
    "for col in numeric_cols:\n",
    "    new_car[col] = new_car_numeric_df[col]\n",
    "\n",
    "# Ensure the new car has the same columns as training data\n",
    "new_car = new_car[X.columns]\n",
    "\n",
    "# Make prediction\n",
    "xgb_pred = model.predict(new_car)\n",
    "\n",
    "# Print predicted price in MAD\n",
    "print(\"\\nPredicted Price for Volkswagen Tiguan (2009, 200000 km, 8 CV, Automatique, Diesel, Excellent):\")\n",
    "print(f\"XGBoost: {xgb_pred[0]:.2f} MAD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa778ef",
   "metadata": {},
   "source": [
    "**Sauvegarde du modèle et des objets nécessaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3564c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le scaler, le modèle, les colonnes et les label encoders ont été sauvegardés sous forme de fichiers .pkl.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le scaler\n",
    "# Définir le chemin du dossier pkl à la racine du projet\n",
    "pkl_dir = os.path.join(project_root, 'pkl-files')\n",
    "os.makedirs(pkl_dir, exist_ok=True)\n",
    "\n",
    "# Sauvegarder le scaler\n",
    "joblib.dump(scaler, os.path.join(pkl_dir, 'xgboost_scaler.pkl'))\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "joblib.dump(model, os.path.join(pkl_dir, 'xgboost_model.pkl'))\n",
    "\n",
    "# Sauvegarder les colonnes utilisées\n",
    "joblib.dump(X.columns, os.path.join(pkl_dir, 'xgboost_columns.pkl'))\n",
    "\n",
    "# Sauvegarder les label encoders\n",
    "joblib.dump(label_encoders, os.path.join(pkl_dir, 'xgboost_label_encoders.pkl'))\n",
    "\n",
    "print(\"Le scaler, le modèle, les colonnes et les label encoders ont été sauvegardés sous forme de fichiers .pkl.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710ac89",
   "metadata": {},
   "source": [
    "**Travail Réalisé par EL ANNASI Nada et EL-GHEFYRY Salma**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
